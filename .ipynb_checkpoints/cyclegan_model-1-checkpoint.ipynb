{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4262b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import IPython\n",
    "from scipy.linalg import svd\n",
    "from numpy import load, zeros, ones, asarray, vstack\n",
    "from numpy.random import randint\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation, Concatenate, Layer, InputSpec, Input, Conv1D, Conv1DTranspose\n",
    "from keras import initializers, regularizers, constraints, backend as K\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9e6c7",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d012d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance normalizer\n",
    "class InstanceNormalization(Layer):\n",
    "    def __init__(self,\n",
    "                 axis=None,\n",
    "                 epsilon=1e-3,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        ndim = len(input_shape)\n",
    "        if self.axis == 0:\n",
    "            raise ValueError('Axis cannot be zero')\n",
    "\n",
    "        if (self.axis is not None) and (ndim == 2):\n",
    "            raise ValueError('Cannot specify axis for rank 1 tensor')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=ndim)\n",
    "\n",
    "        if self.axis is None:\n",
    "            shape = (1,)\n",
    "        else:\n",
    "            shape = (input_shape[self.axis],)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        reduction_axes = list(range(0, len(input_shape)))\n",
    "\n",
    "        if self.axis is not None:\n",
    "            del reduction_axes[self.axis]\n",
    "\n",
    "        del reduction_axes[0]\n",
    "\n",
    "        mean = K.mean(inputs, reduction_axes, keepdims=True)\n",
    "        stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n",
    "        normed = (inputs - mean) / stddev\n",
    "\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        if self.axis is not None:\n",
    "            broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            normed = normed * broadcast_gamma\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            normed = normed + broadcast_beta\n",
    "        return normed\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(InstanceNormalization, self).get_config()\n",
    "\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7b8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch GAN discriminator\n",
    "\n",
    "\"\"\"In a traditional GAN, the discriminator typically outputs a single value indicating whether the entire input image is real or fake. In contrast, a PatchGAN discriminates at the patch level, providing a spatially detailed assessment of the realism of different regions in the input image.\n",
    "The PatchGAN discriminator produces a grid or map of output values, where each value corresponds to the realism of a local patch in the input image. This approach is especially useful for tasks like image-to-image translation, where the goal is to generate realistic high-resolution output images.\"\"\"\n",
    "\n",
    "def create_discriminator(image_shape):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    in_image = Input(shape=image_shape)\n",
    "    d = Conv2D(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = tf.image.resize(d, size=(165, 165), method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "    \n",
    "    patch_out = Conv2D(1, (4, 4), padding='same', kernel_initializer=init)(d)\n",
    "    model = Model(in_image, patch_out)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=0.0002), loss_weights=[0.5])\n",
    "    \"\"\"The loss for the discriminator is weighted by 50% for each model update.\n",
    "    This slows down changes to the discriminator relative to the generator model during training.\"\"\"\n",
    "    return model\n",
    "\n",
    "\n",
    "# def create_discriminator(image_shape):\n",
    "#     init = tf.keras.initializers.HeNormal() #RandomNormal(stddev=0.02)\n",
    "#     in_image = Input(shape=image_shape)\n",
    "#     d = Conv1D(64, 4, strides=2, padding='same', kernel_initializer=init)(in_image)\n",
    "#     d = LeakyReLU(alpha=0.2)(d)\n",
    "#     d = Conv1D(128, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
    "#     d = InstanceNormalization(axis=-1)(d)\n",
    "#     d = LeakyReLU(alpha=0.2)(d)\n",
    "#     d = Conv1D(256, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
    "#     d = InstanceNormalization(axis=-1)(d)\n",
    "#     d = LeakyReLU(alpha=0.2)(d)\n",
    "#     patch_out = Conv1D(1, 4, padding='same', kernel_initializer=init)(d)\n",
    "#     model = Model(in_image, patch_out)\n",
    "#     model.compile(loss='mse', optimizer=Adam(lr=0.0002), loss_weights=[0.5])\n",
    "#     \"\"\"The loss for the discriminator is weighted by 50% for each model update.\n",
    "#     This slows down changes to the discriminator relative to the generator model during training.\"\"\"\n",
    "#     return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e42d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ResNet block\n",
    "def resnet_block(n_filters, input_layer):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    g = Conv2D(n_filters, (3, 3), padding='same', kernel_initializer=init)(input_layer)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    g = Conv2D(n_filters, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Concatenate()([g, input_layer])\n",
    "    return g\n",
    "\n",
    "# Generator model\n",
    "# def create_generator(image_shape, n_resnet=3):\n",
    "#     init = tf.keras.initializers.HeNormal() #RandomNormal(stddev=0.02)\n",
    "#     in_image = Input(shape=image_shape)\n",
    "#     g = Conv2D(64, (7, 7), padding='same', kernel_initializer=init)(in_image)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "# #     g = Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "#     g = Conv2D(128, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "#     g = Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "#     for _ in range(n_resnet):\n",
    "#         g = resnet_block(256, g)\n",
    "#     g = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "#     g = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "#     g = Conv2D(3, (7, 7), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     out_image = Activation('tanh')(g)\n",
    "#     # using tanh as it has bigger gradient, helps againt vanishing gradients\n",
    "#     model = Model(in_image, out_image)\n",
    "#     return model\n",
    "\n",
    "def create_generator(image_shape, n_resnet=3):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    in_image = Input(shape=image_shape)\n",
    "    g = Conv2D(64, (7, 7), padding='same', kernel_initializer=init)(in_image)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "#     g = Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "    g = Conv2D(128, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    g = Conv2D(256, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "#     for _ in range(n_resnet):\n",
    "#         g = resnet_block(256, g)\n",
    "    g = Conv2DTranspose(128, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    g = Conv2DTranspose(64, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    g = Conv2D(1, (7, 7), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # using tanh as it has bigger gradient, helps againt vanishing gradients\n",
    "    model = Model(in_image, out_image)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2526fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite model for updating generators by adversarial and cycle loss\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "    g_model_1.trainable = True\n",
    "    d_model.trainable = False\n",
    "    g_model_2.trainable = False\n",
    "    input_gen = Input(shape=image_shape)\n",
    "    gen1_out = g_model_1(input_gen)\n",
    "    output_d = d_model(gen1_out)\n",
    "    input_id = Input(shape=image_shape)\n",
    "    output_id = g_model_1(input_id)\n",
    "    output_f = g_model_2(gen1_out)\n",
    "    gen2_out = g_model_2(input_id)\n",
    "    output_b = g_model_1(gen2_out)\n",
    "    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=Adam(lr=0.0002))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f9655f",
   "metadata": {},
   "source": [
    "### Data Loading and prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4266c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pixel between -1 and 1 as tanh is used in generator\n",
    "def preprocessing(df):\n",
    "    a,b  = df[0], df[1]\n",
    "    a = (a - 127.5) / 127.5\n",
    "    b = (b - 127.5) / 127.5\n",
    "    return [a, b]\n",
    "\n",
    "# Generate real samples\n",
    "def generate_real_samples(df, n_samples, patch_shape):\n",
    "    ix = randint(0, df.shape[0], n_samples)\n",
    "    X = df[ix]\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "# Generate fake samples\n",
    "def generate_fake_samples(g_model, df, patch_shape):\n",
    "    X = g_model.predict(df)\n",
    "    y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "# Save generator models\n",
    "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
    "    g_model_AtoB.save('trained/g_model_AtoB.h5')\n",
    "    g_model_BtoA.save('trained/g_model_BtoA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62a8bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_path_1 = 'data_2/genres_original/classical'\n",
    "cls_names = sorted([os.path.join(genre_path_1, f) for f in os.listdir(genre_path_1) if os.path.isfile(os.path.join(genre_path_1, f))])\n",
    "\n",
    "genre_path_2 = 'data_2/genres_original/jazz'\n",
    "jzz_names = sorted([os.path.join(genre_path_2, f) for f in os.listdir(genre_path_2) if os.path.isfile(os.path.join(genre_path_2, f)) \\\n",
    "                 and 'jazz.00054.wav' not in f])\n",
    "\n",
    "genre_path_3 = 'data_2/genres_original/country'\n",
    "ctry_names = sorted([os.path.join(genre_path_3, f) for f in os.listdir(genre_path_3) if os.path.isfile(os.path.join(genre_path_3, f))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8376b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rate = 22050\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "\n",
    "def load_and_process_audio(speech_names):\n",
    "    data = [load_audio(x) for x in speech_names]\n",
    "    max_t = max([x.shape[1] for x in data])\n",
    "    data = [pad_zeros(x, max_t) for x in data]\n",
    "    data = np.array(data)\n",
    "    # data = np.transpose(data, (0, 2, 1))\n",
    "    return data\n",
    "\n",
    "def load_audio(speech_name):\n",
    "    s, sr = librosa.load(speech_name, sr=s_rate)\n",
    "    sr = librosa.stft(s, n_fft=n_fft, hop_length=hop_length)\n",
    "    return np.abs(sr)\n",
    "\n",
    "def pad(data, T):\n",
    "    data = [pad_zeros(x, T) for x in data]\n",
    "    return np.array(data)\n",
    "\n",
    "def pad_zeros(sr, T):\n",
    "    return np.pad(sr, ((0, 0), (0, T - sr.shape[1])), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "363e084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = load_and_process_audio(cls_names)\n",
    "jzz = load_and_process_audio(jzz_names)\n",
    "ctry = load_and_process_audio(ctry_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c11e31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1025, 1314) (99, 1025, 1313) (100, 1025, 1308)\n"
     ]
    }
   ],
   "source": [
    "print(cls.shape, jzz.shape, ctry.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26639169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 1025, 1314)\n"
     ]
    }
   ],
   "source": [
    "max_t = max([x[2] for x in [cls.shape, jzz.shape, ctry.shape]])\n",
    "cls = pad(cls, max_t)\n",
    "\n",
    "max_t = max([x[2] for x in [cls.shape, jzz.shape, ctry.shape]])\n",
    "jzz = pad(jzz, max_t)\n",
    "print(jzz.shape)\n",
    "\n",
    "\n",
    "max_t = max([x[2] for x in [cls.shape, jzz.shape, ctry.shape]])\n",
    "ctry = pad(ctry, max_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308031c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = np.transpose(cls, (0, 2, 1))\n",
    "jzz = np.transpose(jzz, (0, 2, 1))\n",
    "ctry = np.transpose(ctry, (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e50c5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_s = cls[np.random.choice(cls.shape[0], size=50, replace=False)]\n",
    "jzz_s = jzz[np.random.choice(jzz.shape[0], size=25, replace=False)]\n",
    "ctry_s = ctry[np.random.choice(ctry.shape[0], size=25, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "459470d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1314, 1025) (25, 1314, 1025) (25, 1314, 1025)\n"
     ]
    }
   ],
   "source": [
    "print(cls_s.shape, jzz_s.shape, ctry_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9ce330",
   "metadata": {},
   "outputs": [],
   "source": [
    "datay = np.concatenate(( jzz_s, ctry_s), axis=0)\n",
    "train_df = [datay, cls_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e2374d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as train_df\n",
    "train_df = preprocessing(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d3364d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 50, 1314, 1025, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = np.array(train_df)\n",
    "train_df.shape\n",
    "train_df = np.expand_dims(train_df,axis = -1)\n",
    "# train_df = train_df.reshape(2,50,1314,1025,1).transpose(0,1,4,2,3)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e833417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eea665",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3428abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = []\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random() < 0.5:\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            ix = randint(0, len(pool))\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return np.asarray(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d861f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs=1):\n",
    "    n_epochs, n_batch = epochs, 1\n",
    "    n_patch = d_model_A.output_shape[1]\n",
    "    trainA, trainB = train_df\n",
    "    poolA, poolB = [], []\n",
    "    bat_per_epo = len(trainA) // n_batch\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "\n",
    "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "        \n",
    "        g_loss2, _, _, _, _ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "        \n",
    "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "        \n",
    "        print('Iteration>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1, dA_loss2, dB_loss1, dB_loss2, g_loss1, g_loss2))\n",
    "        \n",
    "        if (i+1) % (bat_per_epo * 10) == 0:\n",
    "            save_models(i, g_model_AtoB, g_model_BtoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67a5ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "image_shape = train_df[0].shape[1:]\n",
    "\n",
    "g_model_AtoB = create_generator(image_shape)\n",
    "g_model_BtoA = create_generator(image_shape)\n",
    "\n",
    "d_model_A = create_discriminator(image_shape)\n",
    "d_model_B = create_discriminator(image_shape)\n",
    "\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fda93617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 196s 196s/step\n",
      "1/1 [==============================] - 1s 630ms/step\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square' defined at (most recent call last):\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\1899356092.py\", line 2, in <module>\n      train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs=5)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\3119839393.py\", line 18, in train\n      g_loss2, _, _, _, _ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2381, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\2280768116.py\", line 73, in call\n      stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 2893, in std\n      return tf.math.reduce_std(x, axis=axis, keepdims=keepdims)\nNode: 'model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square'\nDetected at node 'model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square' defined at (most recent call last):\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\1899356092.py\", line 2, in <module>\n      train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs=5)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\3119839393.py\", line 18, in train\n      g_loss2, _, _, _, _ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2381, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\2280768116.py\", line 73, in call\n      stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 2893, in std\n      return tf.math.reduce_std(x, axis=axis, keepdims=keepdims)\nNode: 'model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[model_5/model_2/leaky_re_lu_2/LeakyRelu/_12]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_11857]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4388\\1899356092.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#call for train fuction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_model_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_model_AtoB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_model_BtoA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_model_AtoB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_model_BtoA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4388\\3119839393.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mX_fakeB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_image_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoolB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fakeB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mg_loss2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_model_BtoA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_realB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my_realA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mdA_loss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_model_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_realA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mdA_loss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_model_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fakeA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fakeA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2379\u001b[0m             )\n\u001b[0;32m   2380\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2381\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2383\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square' defined at (most recent call last):\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\1899356092.py\", line 2, in <module>\n      train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs=5)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\3119839393.py\", line 18, in train\n      g_loss2, _, _, _, _ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2381, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\2280768116.py\", line 73, in call\n      stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 2893, in std\n      return tf.math.reduce_std(x, axis=axis, keepdims=keepdims)\nNode: 'model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square'\nDetected at node 'model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square' defined at (most recent call last):\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\1899356092.py\", line 2, in <module>\n      train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs=5)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\3119839393.py\", line 18, in train\n      g_loss2, _, _, _, _ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2381, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\meetp\\AppData\\Local\\Temp\\ipykernel_4388\\2280768116.py\", line 73, in call\n      stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n    File \"C:\\Users\\meetp\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 2893, in std\n      return tf.math.reduce_std(x, axis=axis, keepdims=keepdims)\nNode: 'model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[model_5/model_2/leaky_re_lu_2/LeakyRelu/_12]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  failed to allocate memory\n\t [[{{node model_5/model/instance_normalization_2/reduce_std/reduce_variance/Square}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_11857]"
     ]
    }
   ],
   "source": [
    "#call for train fuction\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513da51",
   "metadata": {},
   "source": [
    "### Performance testing (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fa82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a single sample, name is real_A\n",
    "# convert it: -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model if not loaded\n",
    "\n",
    "# model_AtoB = load_model('trained/g_model_AtoB.h5')\n",
    "# model_BtoA = load_model('trained/g_model_BtoA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_hat = model_AtoB.predict(real_A)\n",
    "A_hat = model_BtoA.predict(B_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39539cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert predictions to audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
