{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4262b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import IPython\n",
    "from scipy.linalg import svd\n",
    "from numpy import load, zeros, ones, asarray, vstack\n",
    "from numpy.random import randint\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation, Concatenate, Layer, InputSpec, Input, Conv1D, Conv1DTranspose\n",
    "from keras import initializers, regularizers, constraints, backend as K\n",
    "from matplotlib import pyplot\n",
    "from music21 import midi\n",
    "from midiutil import MIDIFile\n",
    "import fluidsynth\n",
    "from pydub import AudioSegment\n",
    "import IPython.display as ipd\n",
    "from pretty_midi import PrettyMIDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9e6c7",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d012d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance normalizer\n",
    "# Refrenced from: https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/layers/normalization/instancenormalization.py\n",
    "\n",
    "class InstanceNormalization(Layer):\n",
    "    def __init__(self,\n",
    "                 axis=None,\n",
    "                 epsilon=1e-3,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        ndim = len(input_shape)\n",
    "        if self.axis == 0:\n",
    "            raise ValueError('Axis cannot be zero')\n",
    "\n",
    "        if (self.axis is not None) and (ndim == 2):\n",
    "            raise ValueError('Cannot specify axis for rank 1 tensor')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=ndim)\n",
    "\n",
    "        if self.axis is None:\n",
    "            shape = (1,)\n",
    "        else:\n",
    "            shape = (input_shape[self.axis],)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        reduction_axes = list(range(0, len(input_shape)))\n",
    "\n",
    "        if self.axis is not None:\n",
    "            del reduction_axes[self.axis]\n",
    "\n",
    "        del reduction_axes[0]\n",
    "\n",
    "        mean = K.mean(inputs, reduction_axes, keepdims=True)\n",
    "        stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n",
    "        normed = (inputs - mean) / stddev\n",
    "\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        if self.axis is not None:\n",
    "            broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            normed = normed * broadcast_gamma\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            normed = normed + broadcast_beta\n",
    "        return normed\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(InstanceNormalization, self).get_config()\n",
    "\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c7b8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch GAN discriminator\n",
    "\n",
    "\"\"\"In a traditional GAN, the discriminator typically outputs a single value indicating whether the entire input image is real or fake. In contrast, a PatchGAN discriminates at the patch level, providing a spatially detailed assessment of the realism of different regions in the input image.\n",
    "The PatchGAN discriminator produces a grid or map of output values, where each value corresponds to the realism of a local patch in the input image. This approach is especially useful for tasks like image-to-image translation, where the goal is to generate realistic high-resolution output images.\"\"\"\n",
    "\n",
    "def create_discriminator(image_shape):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    in_image = Input(shape=image_shape)\n",
    "    d = Conv2D(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = tf.image.resize(d, size=(165, 165), method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "    \n",
    "    patch_out = Conv2D(1, (4, 4), padding='same', kernel_initializer=init)(d)\n",
    "    model = Model(in_image, patch_out)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=0.0002), loss_weights=[0.5])\n",
    "    \"\"\"The loss for the discriminator is weighted by 50% for each model update.\n",
    "    This slows down changes to the discriminator relative to the generator model during training.\"\"\"\n",
    "    return model\n",
    "\n",
    "\n",
    "# def create_discriminator(image_shape):\n",
    "#     init = tf.keras.initializers.HeNormal() #RandomNormal(stddev=0.02)\n",
    "#     in_image = Input(shape=image_shape)\n",
    "#     d = Conv1D(64, 4, strides=2, padding='same', kernel_initializer=init)(in_image)\n",
    "#     d = LeakyReLU(alpha=0.2)(d)\n",
    "#     d = Conv1D(128, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
    "#     d = InstanceNormalization(axis=-1)(d)\n",
    "#     d = LeakyReLU(alpha=0.2)(d)\n",
    "#     d = Conv1D(256, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
    "#     d = InstanceNormalization(axis=-1)(d)\n",
    "#     d = LeakyReLU(alpha=0.2)(d)\n",
    "#     patch_out = Conv1D(1, 4, padding='same', kernel_initializer=init)(d)\n",
    "#     model = Model(in_image, patch_out)\n",
    "#     model.compile(loss='mse', optimizer=Adam(lr=0.0002), loss_weights=[0.5])\n",
    "#     \"\"\"The loss for the discriminator is weighted by 50% for each model update.\n",
    "#     This slows down changes to the discriminator relative to the generator model during training.\"\"\"\n",
    "#     return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7e42d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ResNet block\n",
    "def resnet_block(n_filters, input_layer):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    g = Conv2D(n_filters, (3, 3), padding='same', kernel_initializer=init)(input_layer)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    g = Conv2D(n_filters, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Concatenate()([g, input_layer])\n",
    "    return g\n",
    "\n",
    "# Generator model\n",
    "# def create_generator(image_shape, n_resnet=3):\n",
    "#     init = tf.keras.initializers.HeNormal() #RandomNormal(stddev=0.02)\n",
    "#     in_image = Input(shape=image_shape)\n",
    "#     g = Conv2D(64, (7, 7), padding='same', kernel_initializer=init)(in_image)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "# #     g = Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "#     g = Conv2D(128, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "#     g = Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "#     for _ in range(n_resnet):\n",
    "#         g = resnet_block(256, g)\n",
    "#     g = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "#     g = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     g = Activation('relu')(g)\n",
    "#     g = Conv2D(3, (7, 7), padding='same', kernel_initializer=init)(g)\n",
    "#     g = InstanceNormalization(axis=-1)(g)\n",
    "#     out_image = Activation('tanh')(g)\n",
    "#     # using tanh as it has bigger gradient, helps againt vanishing gradients\n",
    "#     model = Model(in_image, out_image)\n",
    "#     return model\n",
    "\n",
    "def create_generator(image_shape, n_resnet=3):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    in_image = Input(shape=image_shape)\n",
    "    g = Conv2D(64, (7, 7), padding='same', kernel_initializer=init)(in_image)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "#     g = Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
    "    g = Conv2D(128, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    g = Conv2D(256, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "#     for _ in range(n_resnet):\n",
    "#         g = resnet_block(256, g)\n",
    "    g = Conv2DTranspose(128, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    g = Conv2DTranspose(64, (3, 3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    g = Conv2D(1, (7, 7), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # using tanh as it has bigger gradient, helps againt vanishing gradients\n",
    "    model = Model(in_image, out_image)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2526fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite model for updating generators by adversarial and cycle loss\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "    g_model_1.trainable = True\n",
    "    d_model.trainable = False\n",
    "    g_model_2.trainable = False\n",
    "    input_gen = Input(shape=image_shape)\n",
    "    gen1_out = g_model_1(input_gen)\n",
    "    output_d = d_model(gen1_out)\n",
    "    input_id = Input(shape=image_shape)\n",
    "    output_id = g_model_1(input_id)\n",
    "    output_f = g_model_2(gen1_out)\n",
    "    gen2_out = g_model_2(input_id)\n",
    "    output_b = g_model_1(gen2_out)\n",
    "    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=Adam(lr=0.0002))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f9655f",
   "metadata": {},
   "source": [
    "### Data Loading and prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4266c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate real samples\n",
    "def generate_real_samples(df, n_samples, patch_shape):\n",
    "    ix = randint(0, df.shape[0], n_samples)\n",
    "    X = df[ix]\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "# Generate fake samples\n",
    "def generate_fake_samples(g_model, df, patch_shape):\n",
    "    X = g_model.predict(df)\n",
    "    y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "# Save generator models\n",
    "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
    "    g_model_AtoB.save('trained/g_model_AtoB.h5')\n",
    "    g_model_BtoA.save('trained/g_model_BtoA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec166f6d-2283-470a-b1d9-b59730fa5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_path_1 = '../dataset/JC_C/train'\n",
    "JC_C_names = sorted([os.path.join(genre_path_1, f) for f in os.listdir(genre_path_1) if os.path.isfile(os.path.join(genre_path_1, f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef6d4b3d-7668-44c9-b4cf-93b2ee4e4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_path_2 = '../dataset/JC_J/train'\n",
    "JC_J_names = sorted([os.path.join(genre_path_2, f) for f in os.listdir(genre_path_2) if os.path.isfile(os.path.join(genre_path_2, f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54c2bd3c-7fad-4223-aa2d-38b74f4fa5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 64, 84, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JC_C_np = np.array([np.load(x) for x in JC_C_names[:10000]])\n",
    "JC_C_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff6c5613-82fa-4892-9619-6b3dd05c15f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 64, 84, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JC_J_np = np.array([np.load(x) for x in JC_J_names[:10000]])\n",
    "JC_J_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9276ec7-ab0a-43df-b742-a461447626ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = JC_C_np.reshape((10000, 1, 64, 84, 1))\n",
    "# B = JC_J_np.reshape((10000, 1, 64, 84, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8abf24d6-9d1f-485c-999a-e8d01590f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df4af080-4433-47d5-9417-5116f94ed04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_B_dataset = np.array([JC_C_np, JC_J_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "321f96c9-4223-434e-b74c-b7c59daa105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10000, 64, 84, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_B_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db9ce330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datay = np.concatenate(( jzz_s, ctry_s), axis=0)\n",
    "# train_df = [datay, cls_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e2374d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as train_df\n",
    "# train_df = preprocessing(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d3364d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_df = np.array(train_df)\n",
    "# train_df.shape\n",
    "# train_df = np.expand_dims(train_df,axis = -1)\n",
    "# # train_df = train_df.reshape(2,50,1314,1025,1).transpose(0,1,4,2,3)\n",
    "# train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e833417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eea665",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3428abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = []\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random() < 0.5:\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            ix = randint(0, len(pool))\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return np.asarray(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d861f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs=1):\n",
    "    n_epochs, n_batch = epochs, 1\n",
    "    n_patch = d_model_A.output_shape[1]\n",
    "    trainA, trainB = A_B_dataset\n",
    "    poolA, poolB = [], []\n",
    "    bat_per_epo = len(trainA) // n_batch\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "\n",
    "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "        \n",
    "        g_loss2, _, _, _, _ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "        \n",
    "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "        \n",
    "        print('Iteration>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1, dA_loss2, dB_loss1, dB_loss2, g_loss1, g_loss2))\n",
    "        \n",
    "        if (i+1) % (bat_per_epo * 10) == 0:\n",
    "            save_models(i, g_model_AtoB, g_model_BtoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67a5ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityaramachandra/miniconda3/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "image_shape = A_B_dataset[0].shape[1:]\n",
    "\n",
    "g_model_AtoB = create_generator(image_shape)\n",
    "g_model_BtoA = create_generator(image_shape)\n",
    "\n",
    "d_model_A = create_discriminator(image_shape)\n",
    "d_model_B = create_discriminator(image_shape)\n",
    "\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda93617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 20:57:21.317890: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 771ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 20:57:23.871620: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    }
   ],
   "source": [
    "#call for train fuction\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513da51",
   "metadata": {},
   "source": [
    "### Performance testing (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fa82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a single sample, name is real_A\n",
    "# convert it: -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model if not loaded\n",
    "\n",
    "# model_AtoB = load_model('trained/g_model_AtoB.h5')\n",
    "# model_BtoA = load_model('trained/g_model_BtoA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_hat = model_AtoB.predict(real_A)\n",
    "A_hat = model_BtoA.predict(B_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39539cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert predictions to audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
